{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<i>Copyright (c) Recommenders contributors.</i>\n",
                "\n",
                "<i>Licensed under the MIT License.</i>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Benchmark with Movielens dataset\n",
                "\n",
                "This illustrative comparison applies to collaborative filtering algorithms available in this repository such as Spark ALS, Surprise SVD, SAR and others using the Movielens dataset. These algorithms are usable in a variety of recommendation tasks, including product or news recommendations.\n",
                "\n",
                "The main purpose of this notebook is not to produce comprehensive benchmarking results on multiple datasets. Rather, it is intended to illustrate on how one could evaluate different recommender algorithms using tools in this repository.\n",
                "\n",
                "## Experimentation setup:\n",
                "\n",
                "* Objective\n",
                "  * To compare how each collaborative filtering algorithm perform in predicting ratings and recommending relevant items.\n",
                "\n",
                "* Environment\n",
                "  * The comparison is run on a machine with 4 CPUs, 30Gb of RAM, and 1 GPU GeForce GTX 1660 Ti with 6Gb of memory.\n",
                "  * It should be noted that a local machine is not supposed to run scalable benchmarking analysis. Either scaling up or out the computing instances is necessary to run the benchmarking in an run-time efficient way without any memory issue.\n",
                "  * **NOTE ABOUT THE DEPENDENCIES TO INSTALL**: This notebook uses CPU, GPU and PySpark algorithms, so make sure you install the `full environment` as detailed in the [SETUP.md](../../SETUP.md). \n",
                "  \n",
                "* Datasets\n",
                "  * [Movielens 100K](https://grouplens.org/datasets/movielens/100k/).\n",
                "  * [Movielens 1M](https://grouplens.org/datasets/movielens/1m/).\n",
                "\n",
                "* Data split\n",
                "  * The data is split into train and test sets.\n",
                "  * The split ratios are 75-25 for train and test datasets.\n",
                "  * The splitting is stratified based on items. \n",
                "\n",
                "* Model training\n",
                "  * A recommendation model is trained by using each of the collaborative filtering algorithms. \n",
                "  * Empirical parameter values reported [here](http://mymedialite.net/examples/datasets.html) are used in this notebook. More exhaustive hyper parameter tuning would be required to further optimize results.\n",
                "\n",
                "* Evaluation metrics\n",
                "  * Ranking metrics:\n",
                "    * Precision@k.\n",
                "    * Recall@k.\n",
                "    * Normalized discounted cumulative gain@k (NDCG@k).\n",
                "    * Mean-average-precision (MAP). \n",
                "    * In the evaluation metrics above, k = 10. \n",
                "  * Rating metrics:\n",
                "    * Root mean squared error (RMSE).\n",
                "    * Mean average error (MAE).\n",
                "    * R squared.\n",
                "    * Explained variance.\n",
                "  * Run time performance\n",
                "    * Elapsed for training a model and using a model for predicting/recommending k items. \n",
                "    * The time may vary across different machines. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Globals settings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove warnings\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "import os\n",
                "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
                "os.environ[\"SPARK_LOCAL_IP\"] = \"127.0.0.1\"  # Set local IP to avoid hostname warnings\n",
                "import logging\n",
                "logging.basicConfig(level=logging.ERROR)\n",
                "logging.getLogger(\"py4j\").setLevel(logging.ERROR)\n",
                "logging.getLogger(\"pyspark\").setLevel(logging.ERROR)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "System version: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]\n",
                        "Number of cores: 8\n",
                        "NumPy version: 1.26.4\n",
                        "Pandas version: 2.2.2\n",
                        "Cornac version: 2.3.0\n",
                        "Surprise version: 1.1.4\n",
                        "PySpark version: 3.5.1\n",
                        "CUDA version: 12.1\n",
                        "CuDNN version: 8902\n",
                        "TensorFlow version: 2.15.1\n",
                        "PyTorch version: 2.3.1+cu121\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import cornac\n",
                "\n",
                "try:\n",
                "    import pyspark\n",
                "    from recommenders.utils.spark_utils import start_or_get_spark\n",
                "except ImportError:\n",
                "    pass  # skip this import if we are not in a Spark environment\n",
                "\n",
                "try:\n",
                "    import tensorflow as tf # NOTE: TF needs to be imported before PyTorch, otherwise we get an error\n",
                "    tf.get_logger().setLevel(\"ERROR\") # only show error messages\n",
                "    import torch\n",
                "    from recommenders.utils.gpu_utils import get_cuda_version, get_cudnn_version\n",
                "except ImportError:\n",
                "    pass  # skip this import if we are not in a GPU environment\n",
                "\n",
                "try:\n",
                "    import surprise # Put SVD surprise back in core deps when #2224 is fixed\n",
                "except:\n",
                "    pass \n",
                "\n",
                "current_path = os.path.join(os.getcwd(), \"examples\", \"06_benchmarks\") # To execute the notebook programmatically from root folder\n",
                "sys.path.append(current_path)\n",
                "from benchmark_utils import * \n",
                "from recommenders.datasets import movielens\n",
                "from recommenders.utils.general_utils import get_number_processors\n",
                "from recommenders.datasets.python_splitters import python_stratified_split\n",
                "from recommenders.utils.notebook_utils import store_metadata\n",
                "\n",
                "\n",
                "print(f\"System version: {sys.version}\")\n",
                "print(f\"Number of cores: {get_number_processors()}\")\n",
                "print(f\"NumPy version: {np.__version__}\")\n",
                "print(f\"Pandas version: {pd.__version__}\")\n",
                "print(f\"Cornac version: {cornac.__version__}\")\n",
                "\n",
                "try:\n",
                "    print(f\"Surprise version: {surprise.__version__}\") # Put SVD surprise back in core deps when #2224 is fixed\n",
                "except NameError:\n",
                "    pass\n",
                "\n",
                "try:\n",
                "    print(f\"PySpark version: {pyspark.__version__}\")\n",
                "except NameError:\n",
                "    pass  # skip this import if we are not in a Spark environment\n",
                "\n",
                "try:\n",
                "    print(f\"CUDA version: {get_cuda_version()}\")\n",
                "    print(f\"CuDNN version: {get_cudnn_version()}\")\n",
                "    print(f\"TensorFlow version: {tf.__version__}\")\n",
                "    print(f\"PyTorch version: {torch.__version__}\")\n",
                "except NameError:\n",
                "    pass  # skip this import if we are not in a GPU environment\n",
                "\n",
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    spark = start_or_get_spark(\"PySpark\", memory=\"32g\")\n",
                "    spark.conf.set(\"spark.sql.analyzer.failAmbiguousSelfJoin\", \"false\")\n",
                "    # Suppress Spark warnings\n",
                "    spark.sparkContext.setLogLevel(\"ERROR\")    \n",
                "    log4j = spark._jvm.org.apache.log4j\n",
                "    log4j.LogManager.getLogger(\"org\").setLevel(log4j.Level.ERROR)\n",
                "    log4j.LogManager.getLogger(\"akka\").setLevel(log4j.Level.ERROR)\n",
                "    log4j.LogManager.getLogger(\"org.apache.spark\").setLevel(log4j.Level.ERROR)\n",
                "    log4j.LogManager.getLogger(\"org.spark_project\").setLevel(log4j.Level.ERROR)\n",
                "except NameError:\n",
                "    pass  # skip this import if we are not in a Spark environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fix random seeds to make sure out runs are reproducible\n",
                "np.random.seed(SEED)\n",
                "try:\n",
                "    tf.random.set_seed(SEED)\n",
                "    torch.manual_seed(SEED)\n",
                "    torch.cuda.manual_seed_all(SEED)\n",
                "except NameError:\n",
                "    pass  # skip this import if we are not in a GPU environment"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "data_sizes = [\"100k\"] # Movielens data size: 100k, 1m, 10m, or 20m\n",
                "algorithms = [\"als\", \"svd\", \"sar\", \"ncf\", \"embdotbias\", \"bpr\", \"bivae\", \"lightgcn\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "environments = {\n",
                "    \"als\": \"pyspark\",\n",
                "    \"sar\": \"python_cpu\",\n",
                "    \"svd\": \"python_cpu\",\n",
                "    \"embdotbias\": \"python_gpu\",\n",
                "    \"ncf\": \"python_gpu\",\n",
                "    \"bpr\": \"python_cpu\",\n",
                "    \"bivae\": \"python_gpu\",\n",
                "    \"lightgcn\": \"python_gpu\",\n",
                "}\n",
                "\n",
                "metrics = {\n",
                "    \"als\": [\"rating\", \"ranking\"],\n",
                "    \"sar\": [\"ranking\"],\n",
                "    \"svd\": [\"rating\", \"ranking\"],\n",
                "    \"embdotbias\": [\"rating\", \"ranking\"],\n",
                "    \"ncf\": [\"ranking\"],\n",
                "    \"bpr\": [\"ranking\"],\n",
                "    \"bivae\": [\"ranking\"],\n",
                "    \"lightgcn\": [\"ranking\"]\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Algorithm parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "als_params = {\n",
                "    \"rank\": 10,\n",
                "    \"maxIter\": 20,\n",
                "    \"implicitPrefs\": False,\n",
                "    \"alpha\": 0.1,\n",
                "    \"regParam\": 0.05,\n",
                "    \"coldStartStrategy\": \"drop\",\n",
                "    \"nonnegative\": False,\n",
                "    \"userCol\": DEFAULT_USER_COL,\n",
                "    \"itemCol\": DEFAULT_ITEM_COL,\n",
                "    \"ratingCol\": DEFAULT_RATING_COL,\n",
                "}\n",
                "\n",
                "sar_params = {\n",
                "    \"similarity_type\": \"jaccard\",\n",
                "    \"time_decay_coefficient\": 30,\n",
                "    \"time_now\": None,\n",
                "    \"timedecay_formula\": True,\n",
                "    \"col_user\": DEFAULT_USER_COL,\n",
                "    \"col_item\": DEFAULT_ITEM_COL,\n",
                "    \"col_rating\": DEFAULT_RATING_COL,\n",
                "    \"col_timestamp\": DEFAULT_TIMESTAMP_COL,\n",
                "}\n",
                "\n",
                "svd_params = {\n",
                "    \"n_factors\": 150,\n",
                "    \"n_epochs\": 15,\n",
                "    \"lr_all\": 0.005,\n",
                "    \"reg_all\": 0.02,\n",
                "    \"random_state\": SEED,\n",
                "    \"verbose\": False\n",
                "}\n",
                "\n",
                "embdotbias_params = {\n",
                "    \"n_factors\": 40, \n",
                "    \"y_range\": [0,5.5], \n",
                "    \"wd\": 1e-1,\n",
                "    \"lr_max\": 5e-3,\n",
                "    \"epochs\": 15\n",
                "}\n",
                "\n",
                "ncf_params = {\n",
                "    \"model_type\": \"NeuMF\",\n",
                "    \"n_factors\": 4,\n",
                "    \"layer_sizes\": [16, 8, 4],\n",
                "    \"n_epochs\": 15,\n",
                "    \"batch_size\": 1024,\n",
                "    \"learning_rate\": 1e-3,\n",
                "    \"verbose\": 10\n",
                "}\n",
                "\n",
                "bpr_params = {\n",
                "    \"k\": 200,\n",
                "    \"max_iter\": 200,\n",
                "    \"learning_rate\": 0.01,\n",
                "    \"lambda_reg\": 1e-3,\n",
                "    \"seed\": SEED,\n",
                "    \"verbose\": False\n",
                "}\n",
                "\n",
                "bivae_params = {\n",
                "    \"k\": 100,\n",
                "    \"encoder_structure\": [200],\n",
                "    \"act_fn\": \"tanh\",\n",
                "    \"likelihood\": \"pois\",\n",
                "    \"n_epochs\": 500,\n",
                "    \"batch_size\": 1024,\n",
                "    \"learning_rate\": 0.001,\n",
                "    \"seed\": SEED,\n",
                "    \"use_gpu\": True,\n",
                "    \"verbose\": False\n",
                "}\n",
                "\n",
                "lightgcn_param = {\n",
                "    \"model_type\": \"lightgcn\",\n",
                "    \"n_layers\": 3,\n",
                "    \"batch_size\": 1024,\n",
                "    \"embed_size\": 64,\n",
                "    \"decay\": 0.0001,\n",
                "    \"epochs\": 20,\n",
                "    \"learning_rate\": 0.005,\n",
                "    \"eval_epoch\": 5,\n",
                "    \"top_k\": DEFAULT_K,\n",
                "    \"metrics\": [\"recall\", \"ndcg\", \"precision\", \"map\"],\n",
                "    \"save_model\":False,\n",
                "    \"MODEL_DIR\":\".\",\n",
                "}\n",
                "\n",
                "params = {\n",
                "    \"als\": als_params,\n",
                "    \"sar\": sar_params,\n",
                "    \"svd\": svd_params,\n",
                "    \"embdotbias\": embdotbias_params,\n",
                "    \"ncf\": ncf_params,\n",
                "    \"bpr\": bpr_params,\n",
                "    \"bivae\": bivae_params,\n",
                "    \"lightgcn\": lightgcn_param,\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "prepare_training_data = {\n",
                "    \"als\": prepare_training_als,\n",
                "    \"sar\": prepare_training_sar,\n",
                "    \"svd\": prepare_training_svd,\n",
                "    \"embdotbias\": prepare_training_embdotbias,\n",
                "    \"ncf\": prepare_training_ncf,\n",
                "    \"bpr\": prepare_training_cornac,\n",
                "    \"bivae\": prepare_training_cornac,\n",
                "    \"lightgcn\": prepare_training_lightgcn,\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "prepare_metrics_data = {\n",
                "    \"als\": lambda train, test: prepare_metrics_als(train, test),\n",
                "    \"embdotbias\": lambda train, test: prepare_metrics_embdotbias(train, test),    \n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "trainer = {\n",
                "    \"als\": lambda params, data: train_als(params, data),\n",
                "    \"svd\": lambda params, data: train_svd(params, data),\n",
                "    \"sar\": lambda params, data: train_sar(params, data), \n",
                "    \"embdotbias\": lambda params, data: train_embdotbias(params, data),\n",
                "    \"ncf\": lambda params, data: train_ncf(params, data),\n",
                "    \"bpr\": lambda params, data: train_bpr(params, data),\n",
                "    \"bivae\": lambda params, data: train_bivae(params, data),\n",
                "    \"lightgcn\": lambda params, data: train_lightgcn(params, data),\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "rating_predictor = {\n",
                "    \"als\": lambda model, test: predict_als(model, test),\n",
                "    \"svd\": lambda model, test: predict_svd(model, test),\n",
                "    \"embdotbias\": lambda model, test: predict_embdotbias(model, test),\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "ranking_predictor = {\n",
                "    \"als\": lambda model, test, train: recommend_k_als(model, test, train),\n",
                "    \"sar\": lambda model, test, train: recommend_k_sar(model, test, train),\n",
                "    \"svd\": lambda model, test, train: recommend_k_svd(model, test, train),\n",
                "    \"embdotbias\": lambda model, test, train: recommend_k_embdotbias(model, test, train),\n",
                "    \"ncf\": lambda model, test, train: recommend_k_ncf(model, test, train),\n",
                "    \"bpr\": lambda model, test, train: recommend_k_cornac(model, test, train),\n",
                "    \"bivae\": lambda model, test, train: recommend_k_cornac(model, test, train),\n",
                "    \"lightgcn\": lambda model, test, train: recommend_k_lightgcn(model, test, train),\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "rating_evaluator = {\n",
                "    \"als\": lambda test, predictions: rating_metrics_pyspark(test, predictions),\n",
                "    \"svd\": lambda test, predictions: rating_metrics_python(test, predictions),\n",
                "    \"embdotbias\": lambda test, predictions: rating_metrics_python(test, predictions)\n",
                "}\n",
                "    \n",
                "    \n",
                "ranking_evaluator = {\n",
                "    \"als\": lambda test, predictions, k: ranking_metrics_pyspark(test, predictions, k),\n",
                "    \"sar\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
                "    \"svd\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
                "    \"embdotbias\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
                "    \"ncf\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
                "    \"bpr\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
                "    \"bivae\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
                "    \"lightgcn\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_summary(data, algo, k, train_time, time_rating, rating_metrics, time_ranking, ranking_metrics):\n",
                "    summary = {\"Data\": data, \"Algo\": algo, \"K\": k, \"Train time (s)\": train_time, \"Predicting time (s)\": time_rating, \"Recommending time (s)\": time_ranking}\n",
                "    if rating_metrics is None:\n",
                "        rating_metrics = {\n",
                "            \"RMSE\": np.nan,\n",
                "            \"MAE\": np.nan,\n",
                "            \"R2\": np.nan,\n",
                "            \"Explained Variance\": np.nan,\n",
                "        }\n",
                "    if ranking_metrics is None:\n",
                "        ranking_metrics = {\n",
                "            \"MAP\": np.nan,\n",
                "            \"nDCG@k\": np.nan,\n",
                "            \"Precision@k\": np.nan,\n",
                "            \"Recall@k\": np.nan,\n",
                "        }\n",
                "    summary.update(rating_metrics)\n",
                "    summary.update(ranking_metrics)\n",
                "    return summary"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Benchmark loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 4.81k/4.81k [00:01<00:00, 3.41kKB/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Size of Movielens 100k: (100000, 4)\n",
                        "\n",
                        "Computing als algorithm on Movielens 100k\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training time: 18.0497s\n",
                        "Rating prediction time: 0.1363s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ranking prediction time: 0.2291s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Computing svd algorithm on Movielens 100k\n",
                        "Training time: 1.4932s\n",
                        "Rating prediction time: 0.2286s\n",
                        "Ranking prediction time: 29.4715s\n",
                        "\n",
                        "Computing sar algorithm on Movielens 100k\n",
                        "Training time: 0.5182s\n",
                        "Ranking prediction time: 0.2746s\n",
                        "\n",
                        "Computing ncf algorithm on Movielens 100k\n",
                        "Training time: 212.0977s\n",
                        "Ranking prediction time: 17.8614s\n",
                        "\n",
                        "Computing embdotbias algorithm on Movielens 100k\n",
                        "Training time: 90.2558s\n",
                        "Rating prediction time: 0.0296s\n",
                        "Ranking prediction time: 1.6731s\n",
                        "\n",
                        "Computing bpr algorithm on Movielens 100k\n",
                        "Training time: 5.0060s\n",
                        "Ranking prediction time: 1.1596s\n",
                        "\n",
                        "Computing bivae algorithm on Movielens 100k\n",
                        "Training time: 22.7007s\n",
                        "Ranking prediction time: 1.3945s\n",
                        "\n",
                        "Computing lightgcn algorithm on Movielens 100k\n",
                        "Already create adjacency matrix.\n",
                        "Already normalize adjacency matrix.\n",
                        "Using xavier initialization.\n",
                        "Epoch 1 (train)2.2s: train loss = 0.47424 = (mf)0.47399 + (embed)0.00024\n",
                        "Epoch 2 (train)1.6s: train loss = 0.28452 = (mf)0.28387 + (embed)0.00065\n",
                        "Epoch 3 (train)1.1s: train loss = 0.25279 = (mf)0.25198 + (embed)0.00082\n",
                        "Epoch 4 (train)1.0s: train loss = 0.23877 = (mf)0.23779 + (embed)0.00098\n",
                        "Epoch 5 (train)1.2s + (eval)0.5s: train loss = 0.23127 = (mf)0.23017 + (embed)0.00109, recall = 0.15908, ndcg = 0.34727, precision = 0.30064, map = 0.21733\n",
                        "Epoch 6 (train)1.1s: train loss = 0.22167 = (mf)0.22048 + (embed)0.00119\n",
                        "Epoch 7 (train)1.2s: train loss = 0.21497 = (mf)0.21366 + (embed)0.00130\n",
                        "Epoch 8 (train)1.1s: train loss = 0.20307 = (mf)0.20162 + (embed)0.00144\n",
                        "Epoch 9 (train)1.3s: train loss = 0.19217 = (mf)0.19058 + (embed)0.00159\n",
                        "Epoch 10 (train)1.2s + (eval)0.2s: train loss = 0.18261 = (mf)0.18086 + (embed)0.00175, recall = 0.18022, ndcg = 0.38983, precision = 0.33733, map = 0.25320\n",
                        "Epoch 11 (train)1.0s: train loss = 0.17686 = (mf)0.17496 + (embed)0.00190\n",
                        "Epoch 12 (train)1.2s: train loss = 0.17242 = (mf)0.17038 + (embed)0.00204\n",
                        "Epoch 13 (train)1.0s: train loss = 0.16767 = (mf)0.16550 + (embed)0.00217\n",
                        "Epoch 14 (train)1.1s: train loss = 0.16560 = (mf)0.16332 + (embed)0.00228\n",
                        "Epoch 15 (train)1.1s + (eval)0.4s: train loss = 0.16428 = (mf)0.16191 + (embed)0.00237, recall = 0.18870, ndcg = 0.39967, precision = 0.34517, map = 0.25996\n",
                        "Epoch 16 (train)1.1s: train loss = 0.16142 = (mf)0.15896 + (embed)0.00247\n",
                        "Epoch 17 (train)1.2s: train loss = 0.15734 = (mf)0.15477 + (embed)0.00256\n",
                        "Epoch 18 (train)1.0s: train loss = 0.15441 = (mf)0.15175 + (embed)0.00266\n",
                        "Epoch 19 (train)1.2s: train loss = 0.15454 = (mf)0.15179 + (embed)0.00275\n",
                        "Epoch 20 (train)1.1s + (eval)0.2s: train loss = 0.15289 = (mf)0.15006 + (embed)0.00283, recall = 0.19425, ndcg = 0.41094, precision = 0.35726, map = 0.27009\n",
                        "Training time: 25.2336s\n",
                        "Ranking prediction time: 0.0481s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 5.78k/5.78k [00:01<00:00, 4.21kKB/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Size of Movielens 1m: (1000209, 4)\n",
                        "\n",
                        "Computing als algorithm on Movielens 1m\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training time: 8.9152s\n",
                        "Rating prediction time: 0.0434s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ranking prediction time: 0.0857s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Computing svd algorithm on Movielens 1m\n",
                        "Training time: 16.3013s\n",
                        "Rating prediction time: 2.0930s\n",
                        "Ranking prediction time: 255.2681s\n",
                        "\n",
                        "Computing sar algorithm on Movielens 1m\n",
                        "Training time: 3.8451s\n",
                        "Ranking prediction time: 3.3706s\n",
                        "\n",
                        "Computing ncf algorithm on Movielens 1m\n",
                        "Training time: 1556.8175s\n",
                        "Ranking prediction time: 127.2471s\n",
                        "\n",
                        "Computing embdotbias algorithm on Movielens 1m\n",
                        "Training time: 1139.2315s\n",
                        "Rating prediction time: 0.4044s\n",
                        "Ranking prediction time: 45.8501s\n",
                        "\n",
                        "Computing bpr algorithm on Movielens 1m\n",
                        "Training time: 98.2821s\n",
                        "Ranking prediction time: 32.9448s\n",
                        "\n",
                        "Computing bivae algorithm on Movielens 1m\n",
                        "Training time: 208.7810s\n",
                        "Ranking prediction time: 30.6615s\n",
                        "\n",
                        "Computing lightgcn algorithm on Movielens 1m\n",
                        "Already create adjacency matrix.\n",
                        "Already normalize adjacency matrix.\n",
                        "Using xavier initialization.\n",
                        "Epoch 1 (train)955.1s: train loss = 0.34751 = (mf)0.34692 + (embed)0.00059\n",
                        "Epoch 2 (train)2697.1s: train loss = 0.28045 = (mf)0.27915 + (embed)0.00130\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "File \u001b[0;32m<timed exec>:33\u001b[0m\n",
                        "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(params, data)\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mals\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m params, data: train_als(params, data),\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m params, data: train_svd(params, data),\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msar\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m params, data: train_sar(params, data), \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membdotbias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m params, data: train_embdotbias(params, data),\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mncf\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m params, data: train_ncf(params, data),\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbpr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m params, data: train_bpr(params, data),\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbivae\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m params, data: train_bivae(params, data),\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlightgcn\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m params, data: \u001b[43mtrain_lightgcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     10\u001b[0m }\n",
                        "File \u001b[0;32m~/MS/recommenders/examples/06_benchmarks/benchmark_utils.py:377\u001b[0m, in \u001b[0;36mtrain_lightgcn\u001b[0;34m(params, data)\u001b[0m\n\u001b[1;32m    375\u001b[0m model \u001b[38;5;241m=\u001b[39m LightGCN(hparams, data)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Timer() \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[0;32m--> 377\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, t\n",
                        "File \u001b[0;32m~/MS/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py:219\u001b[0m, in \u001b[0;36mLightGCN.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_batch):\n\u001b[1;32m    218\u001b[0m     users, pos_items, neg_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtrain_loader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m--> 219\u001b[0m     _, batch_loss, batch_mf_loss, batch_emb_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmf_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memb_loss\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43musers\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43musers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_items\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneg_items\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss \u001b[38;5;241m/\u001b[39m n_batch\n\u001b[1;32m    228\u001b[0m     mf_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_mf_loss \u001b[38;5;241m/\u001b[39m n_batch\n",
                        "File \u001b[0;32m~/anaconda/envs/recommenders311/lib/python3.11/site-packages/tensorflow/python/client/session.py:972\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    969\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    975\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
                        "File \u001b[0;32m~/anaconda/envs/recommenders311/lib/python3.11/site-packages/tensorflow/python/client/session.py:1215\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1215\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
                        "File \u001b[0;32m~/anaconda/envs/recommenders311/lib/python3.11/site-packages/tensorflow/python/client/session.py:1395\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1392\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1398\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
                        "File \u001b[0;32m~/anaconda/envs/recommenders311/lib/python3.11/site-packages/tensorflow/python/client/session.py:1402\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1401\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1404\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
                        "File \u001b[0;32m~/anaconda/envs/recommenders311/lib/python3.11/site-packages/tensorflow/python/client/session.py:1385\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1383\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1384\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1385\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/anaconda/envs/recommenders311/lib/python3.11/site-packages/tensorflow/python/client/session.py:1478\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1477\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1478\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "# For each data size and each algorithm, a recommender is evaluated. \n",
                "cols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\", \"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\"]\n",
                "df_results = pd.DataFrame(columns=cols)\n",
                "\n",
                "for data_size in data_sizes:\n",
                "    # Load the dataset\n",
                "    df = movielens.load_pandas_df(\n",
                "        size=data_size,\n",
                "        header=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\n",
                "    )\n",
                "    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\n",
                "    \n",
                "    # Split the dataset\n",
                "    df_train, df_test = python_stratified_split(df,\n",
                "                                                ratio=0.75, \n",
                "                                                min_rating=1, \n",
                "                                                filter_by=\"item\", \n",
                "                                                col_user=DEFAULT_USER_COL, \n",
                "                                                col_item=DEFAULT_ITEM_COL\n",
                "                                                )\n",
                "   \n",
                "    # Loop through the algos\n",
                "    for algo in algorithms:\n",
                "        print(f\"\\nComputing {algo} algorithm on Movielens {data_size}\")\n",
                "          \n",
                "        # Data prep for training set\n",
                "        train = prepare_training_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n",
                "        \n",
                "        # Get model parameters\n",
                "        model_params = params[algo]\n",
                "          \n",
                "        # Train the model\n",
                "        model, time_train = trainer[algo](model_params, train)\n",
                "        print(f\"Training time: {time_train}s\")\n",
                "                \n",
                "        # Predict and evaluate\n",
                "        train, test = prepare_metrics_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n",
                "        \n",
                "        if \"rating\" in metrics[algo]:   \n",
                "            # Predict for rating\n",
                "            preds, time_rating = rating_predictor[algo](model, test)\n",
                "            print(f\"Rating prediction time: {time_rating}s\")\n",
                "            \n",
                "            # Evaluate for rating\n",
                "            ratings = rating_evaluator[algo](test, preds)\n",
                "        else:\n",
                "            ratings = None\n",
                "            time_rating = np.nan\n",
                "        \n",
                "        if \"ranking\" in metrics[algo]:\n",
                "            # Predict for ranking\n",
                "            top_k_scores, time_ranking = ranking_predictor[algo](model, test, train)\n",
                "            print(f\"Ranking prediction time: {time_ranking}s\")\n",
                "            \n",
                "            # Evaluate for rating\n",
                "            rankings = ranking_evaluator[algo](test, top_k_scores, DEFAULT_K)\n",
                "        else:\n",
                "            rankings = None\n",
                "            time_ranking = np.nan\n",
                "            \n",
                "        # Record results\n",
                "        summary = generate_summary(data_size, algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\n",
                "        df_results.loc[df_results.shape[0] + 1] = summary\n",
                "        \n",
                "print(\"\\nComputation finished\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Record results for tests - ignore this cell\n",
                "for algo in algorithms:\n",
                "    store_metadata(algo, df_results.loc[df_results[\"Algo\"] == algo, \"nDCG@k\"].values[0])\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "recommenders311",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
